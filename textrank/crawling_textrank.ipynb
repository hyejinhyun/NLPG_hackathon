{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from newspaper import Article\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.twitter = Okt()\n",
    "        #stopwords를 효율적으로 수정 혹은 추가\n",
    "        self.stopwords = ['중인' ,'만큼', '마찬가지', '꼬집었', \"한국경제\", \"데일리\", \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\"]\n",
    "        \n",
    "#크롤링 수정\n",
    "    \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "\n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence is not '':\n",
    "                nouns.append(' '.join([noun for noun in self.twitter.nouns(str(sentence))\n",
    "                                        if noun not in self.stopwords and len(noun) > 1]))\n",
    "\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "\n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
    "\n",
    "#레퍼런스 코드 다른 부분 필요한건지\n",
    "#     def draw_graph(self, graph):\n",
    "#         graph = nx.from_numpy_matrix(self.graph_sentence, create_using=nx.MultiDiGraph())\n",
    "#         pos = nx.circular_layout(graph)\n",
    "#         nx.draw_circular(graph)\n",
    "#         labels = {i : i for i in graph.nodes()}\n",
    "#         nx.draw_networkx_labels(graph, pos, labels, font_size=15)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal 부분을 0으로\n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "    \n",
    "        self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "\n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "\n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "\n",
    "\n",
    "#output form을 어떻게 바꿔야할지\n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "\n",
    "        return summary\n",
    "\n",
    "#우리 프로젝트에서는 사용하지 않음 빼도 되는지 더 빼도 되는 부분이 있는지\n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "        \n",
    "        return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_art_body(URL):\n",
    "  a = Article(URL,language='ko')\n",
    "  a.download()\n",
    "  a.parse()\n",
    "  return (a.title,a.text)\n",
    "\n",
    "def get_articles_list():  \n",
    "  with urllib.request.urlopen(\"https://www.hankyung.com/society/1002?hkonly=true\") as response:\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    art_link = soup.select('div.article > span > a')\n",
    "\n",
    "  articles = []\n",
    "\n",
    "  for (i,a) in enumerate(art_link):\n",
    "    #articles[i][0]: 링크, articles[i][1]: 제목, articles[i][2]: 본문\n",
    "    if i == 15:\n",
    "      break\n",
    "    l = a.get('href')\n",
    "    (t,c) = get_art_body(l)\n",
    "    r = TextRank(c).summarize(3)\n",
    "    r = \" \".join(r)\n",
    "    articles.append([t,r,l])  #articles.append([t,c,l,r])\n",
    "    \n",
    "\n",
    "  return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'로또식 중학교 추첨'…엄마들 속탄다\", '서울교육청은 초등학교를 졸업하고 중학교에 진학하는 학생들에게 희망 학교 지원을 따로 받지 않는다. 일부 교육청은 이미 중학교 배정에 지원 제와 근거리 배정 방식을 도입해 운영하고 있다. 세종교육청은 학생들의 진학 희망 학교 지원을 받아 지망 순위에 따라 우선 배정한 뒤 지망 학교에 가지 못한 학생들은 근거리 학교에 추첨 배정한다.', 'https://www.hankyung.com/society/article/2019100821721']\n"
     ]
    }
   ],
   "source": [
    "x = get_articles_list()[0]\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
