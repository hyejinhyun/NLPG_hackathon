{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from newspaper import Article\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.twitter = Okt()\n",
    "        #stopwords를 효율적으로 수정 혹은 추가\n",
    "        self.stopwords = ['', '\\n', '중인' ,'만큼', '마찬가지', '꼬집었', \"한국경제\", \"데일리\", \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\"]\n",
    "        \n",
    "#크롤링 수정\n",
    "    \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)\n",
    "        '''\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        '''    \n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence is not '':\n",
    "                nouns.append(' '.join([noun for noun in self.twitter.nouns(str(sentence))\n",
    "                                        if noun not in self.stopwords and len(noun) > 1]))\n",
    "\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "\n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
    "\n",
    "#레퍼런스 코드 다른 부분 필요한건지\n",
    "#     def draw_graph(self, graph):\n",
    "#         graph = nx.from_numpy_matrix(self.graph_sentence, create_using=nx.MultiDiGraph())\n",
    "#         pos = nx.circular_layout(graph)\n",
    "#         nx.draw_circular(graph)\n",
    "#         labels = {i : i for i in graph.nodes()}\n",
    "#         nx.draw_networkx_labels(graph, pos, labels, font_size=15)\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal 부분을 0으로\n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "    \n",
    "        self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "\n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "\n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "\n",
    "\n",
    "#output form을 어떻게 바꿔야할지\n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        num = len(self.sentences)\n",
    "        if(num>=50):\n",
    "            sent_num = 5\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "\n",
    "        return summary\n",
    "\n",
    "#우리 프로젝트에서는 사용하지 않음 빼도 되는지 더 빼도 되는 부분이 있는지\n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "        \n",
    "        return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_art_body(URL):\n",
    "  a = Article(URL,language='ko')\n",
    "  a.download()\n",
    "  a.parse()\n",
    "  return (a.title,a.text)\n",
    "\n",
    "def get_articles_list():  \n",
    "  with urllib.request.urlopen(\"https://www.hankyung.com/society/1002?hkonly=true\") as response:\n",
    "    html = response.read()\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    art_link = soup.select('div.article > span > a')\n",
    "\n",
    "  articles = []\n",
    "\n",
    "  for (i,a) in enumerate(art_link):\n",
    "    #articles[i][0]: 링크, articles[i][1]: 제목, articles[i][2]: 본문\n",
    "    if i == 15:\n",
    "      break\n",
    "    l = a.get('href')\n",
    "    (t,c) = get_art_body(l)\n",
    "    r = TextRank(c).summarize()\n",
    "    r = \"-\".join(r)\n",
    "    articles.append([t,r,l])  #[[제목,텍스트랭크(1줄요약),링크],...]]\n",
    "    \n",
    "\n",
    "  return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"conn = pymysql.connect(host='127.0.0.1', port=3306, user='root', passwd='171217', db='test', charset='utf8')\\natcList = get_articles_list()\\ntry:\\n  for a in atcList:\\n    with conn.cursor() as cursor:\\n      sql = 'INSERT INTO news (title,content,link) VALUES (%s, %s, %s)'\\n      cursor.execute(sql, (a[0],a[1],a[2]))\\n    conn.commit()\\n    print(cursor.lastrowid)\\n    \\nfinally:\\n    conn.close()\""
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 접속\n",
    "conn = pymysql.connect(host='127.0.0.1', port=3306, user='root', passwd='171217', db='test', charset='utf8')\n",
    "atcList = get_articles_list()\n",
    "try:\n",
    "  for a in atcList:\n",
    "    with conn.cursor() as cursor:\n",
    "      sql = 'INSERT INTO news (title,content,link) VALUES (%s, %s, %s)'\n",
    "      cursor.execute(sql, (a[0],a[1],a[2]))\n",
    "    conn.commit()\n",
    "    print(cursor.lastrowid)\n",
    "    \n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
